{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excitation Energy Transfer and Decoherence #\n",
    "\n",
    "Although the molecular exciton model finds application in many different contexts, its perhaps most common application is to the study of excitation energy transfer (EET). EET is the process by which electromagnetic energy (often sunlight) is absorbed by a material and then transported through that material to another, chemically distinct, region. For obvious regions, EET is of great interest the context of photovoltaics and solar light-harvesting, where the focus is usually on creating or investigating materials in which the *rate* of EET is optimized as a function of various material parameters. \n",
    "\n",
    "In this exercise, we'll examine the process of EET in a **classical** molecular dimer in the presence of **dynamic disorder**, i.e., environment-induced frequency shifts that change as a function of time. Much like the static disorder (i.e., inhomogeneous broadening) we've seen in our earlier simulations, dynamic disorder leads to dephasing and, in spectroscopic line shape functions, to *homogeneous broadening*. Both static and dynamic disorder play a critical role in EET efficiency. \n",
    "\n",
    "\n",
    "\n",
    "## Dynamic Disorder ## \n",
    "\n",
    "In real systems, dynamic disorder is a result of low-frequency vibrational motion that leads to a fluctuation of system site energies with time. In our simulation, we won't treat these low-frequency dynamics explicitly, instead just generating a random frequency trajectory for each system oscillator, a treatment strongly analagous to our implicit treatment of the solvent in Langevin dynamics. \n",
    "\n",
    "As a simple example, the code below plots a simulated frequency trajectory for a single harmonic oscillator, with parameters typical for an Amide I (peptide C=O stretch) vibration. Note that, although the average frequency across the trajectory is near 1670 cm$^{-1}$, the instantaneous value at each time point varies widely from 1640 cm$^{-1}$ to 1700 cm$^{-1}$. In the next section, we'll examine how this type of dynamic disorder affects energy transfer rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "wo = 6.28*50e12        # Oscillator (angular) frequency\n",
    "dt=2.0e-15     # Time-step in seconds\n",
    "Nsteps = 1000\n",
    "taxis = np.arange(0, Nsteps)*dt\n",
    "Wx = np.zeros(Nsteps)\n",
    "Wx[0] = wo\n",
    "Delta = 1.0e+12\n",
    "c = 2.9979e+10\n",
    "for n in range(0,Nsteps-1):\n",
    "    Wx[n+1] = Wx[n] + np.random.normal(0, Delta, (1)) + 0.01*(wo-Wx[n])\n",
    "\n",
    "    \n",
    "plt.plot(taxis*1e+15, Wx/(2.0*math.pi*c))\n",
    "plt.xlabel('Time (fs)')\n",
    "plt.ylabel('Frequency (cm$^{-1}$)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EET in a Coupled Dimer ##\n",
    "\n",
    "As a simple test-system for exploring EET dynamics, we'll consider a dimer of two oscillators with perpendicular dipole moments, which interact (e.g., via dipole-dipole coupling) with a coupling strength $J$. To simulate the EET process, we'll excited the system with a laser pulse whose polarization is parallel to **one** of the two dipole moments and orthogonal to the other. Thus the initial excitation created by the pulse is localized exclusively on Oscillator 1 -- the **donor** -- but can be transferred over time to Oscillator 2 -- the **acceptor**. Because our simulation scheme relies on random oscillator frequencies, we'll need to ensemble-average over many different randomly-sampled trajectories, reporting at the end only the ensemble-averaged quantities that are relevant to macroscopic measurements. \n",
    "\n",
    "\n",
    "The code below defines two functions, ``calc_response()`` and ``fit_data()``. The first function simulates the actual interaction of our dipole system with an ultrafast laser pulse and returns a matrix ``E`` whose columns store the energy of the donor (first column) and acceptor (second column) as a function of simulation time. The second function fits the energy profile of the donor to a functional form consisting of an exponential decay multiplied by a cosine signal. As we'll see, this form is flexible enough to provide a reasonable description of the EET dynamics over a wide range of system parameters. \n",
    "\n",
    "Note that the \"EET time\" generated by the code is the time-scale for the exponential decay process (reflecting energy equilibration between the two oscillators), **not** than the time-scale of the cosine signal that reflects rapid oscillation of energy back and forth between donor and acceptor. In the context of solar light-harvesting, it is usually the exponential time scale that is of interest, since energy must remain localized on the acceptor long enough for the \"next step\" in the energy transfer process to take place (e.g., transfer to another molecule, or a chemical event like charge separation). \n",
    "\n",
    "Finally, it is also noteworthy that, since our simulation is classical, the long-time limit respects the classical *equipartition principle*, meaning that as the system equilibrates the excitation energy will ultimately be shared equally between the two oscillators. **The key distinction between our classical simulation and a quantum energy-transfer process is that quantum statistics violate the equipartition principle** -- so that EET in a quantum system can result in the localization of energy on low-frequency oscillators. This principle has important consequences in solar light-harvesting, as evidenced by the \"energy funnel\" structure apparent in biological light-harvesting complexes, where low-frequency pigments are concentrated near the \"reaction center\" where charge-separation takes place. \n",
    "\n",
    "After browsing through the code, execute the cell and then play with the simulation values by modifying and executing the code under the next heading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "def calc_accel(x,efield, wx, J):\n",
    "    K = M*wx**2\n",
    "    ax = -K*x/M\n",
    "    ax += Qo*efield*Minv*DipMat[:,0]  # Excitation is along Z-axis: so we use DipMat[:,0]\n",
    "    ax[:,0] += -J*x[:,1]*Minv\n",
    "    ax[:,1] += -J*x[:,0]*Minv \n",
    "    return ax\n",
    "\n",
    "def vv_step(x,vx,ax,efield,wx,J):\n",
    "    if(Temp==0):\n",
    "        axrand = 0\n",
    "    else:\n",
    "        axrand = math.sqrt(2.0*kB*Temp*gamma/dt)*np.random.normal(0,1,1)/M\n",
    "    xnew = x + B*dt*vx + 0.5*B*dt*dt*(ax + axrand)\n",
    "    axnew = calc_accel(xnew,efield, wx,J)\n",
    "    vxnew = A*vx + 0.5*dt*(A*ax + axnew + 2.0*B*axrand)\n",
    "    return xnew,vxnew,axnew\n",
    "\n",
    "def gauss_pulse(t):\n",
    "    return np.cos(2.0*math.pi*(t-to)*nu)*np.exp(-((t-to)**2)/(2.0*sigma*sigma))\n",
    "\n",
    "to = 150e-15\n",
    "sigma = 10e-15\n",
    "nu = 50e+12\n",
    "\n",
    "tmax = 10e-12      # Total simulation time in seconds\n",
    "dt=2.0e-15     # Time-step in seconds\n",
    "Nsteps=int(tmax/dt)\n",
    "M=12*(1.66054e-24)   # Mass in g\n",
    "Minv = 1.0/M\n",
    "Qo = 4.803e-10         # Elementary charge in statCoulombs\n",
    "taxis = np.arange(0,Nsteps)*dt   # Time axis (array of time steps)\n",
    "\n",
    "gamma = 0.0e-12  # grams/second\n",
    "hbar=1.0546e-27\n",
    "c = 2.9979e+10\n",
    "kB = 1.38064852e-16                  # erg/K\n",
    "Temp = 0.0                           # K\n",
    "B = 1.0/(1.0 + 0.5*gamma*dt/M)\n",
    "A = B*(1.0 - 0.5*gamma*dt/M)\n",
    "\n",
    "Nsamples = 2000\n",
    "Nosc = 2\n",
    "DipMat = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]])\n",
    "\n",
    "wo = 6.28*50e12        # Oscillator (angular) frequency\n",
    "\n",
    "vaxis = np.fft.fftfreq(Nsteps)/(dt*c)\n",
    "\n",
    "v1 = 1600\n",
    "v2 = 1750\n",
    "ndx1 = np.where(np.abs(vaxis-v1)==np.min(np.abs(vaxis-v1)))[0][0]\n",
    "ndx2 = np.where(np.abs(vaxis-v2)==np.min(np.abs(vaxis-v2)))[0][0]\n",
    "\n",
    "\n",
    "Emax = 50e+4\n",
    "Efield = Emax*gauss_pulse(taxis)\n",
    "def calc_response(JNorm, DeltaNorm, showflag):\n",
    "    \n",
    "    Delta = 1.0e+12*DeltaNorm\n",
    "    J = 10e+3*JNorm\n",
    "    Wo = wo*np.ones((Nsamples,Nosc))\n",
    "    Wx = Wo\n",
    "    X = np.zeros((Nsamples,Nosc))\n",
    "    VX = np.zeros((Nsamples,Nosc))\n",
    "    AX = calc_accel(X, Efield[0], Wx, J)\n",
    "    MuY = np.zeros((Nsteps))\n",
    "    MuZ = np.zeros((Nsteps))\n",
    "    E = np.zeros((Nsteps,Nosc))\n",
    "    #Wx = np.random.normal(wo, 0.1*wo, (Nsamples,Nosc))\n",
    "    Wtraj = np.zeros((Nsteps,Nosc))\n",
    "    for n in range(0,Nsteps):\n",
    "        Wx = Wx + np.random.normal(0, Delta, (Nsamples,Nosc)) + 0.01*(wo-Wx)\n",
    "        Wtraj[n,:] = Wx[0,:]\n",
    "        X,VX,AX = vv_step(X,VX,AX,Efield[n],Wx,J)\n",
    "        MuY[n] = np.mean(X*DipMat[:,1])*Qo\n",
    "        MuZ[n] = np.mean(X*DipMat[:,0])*Qo\n",
    "        E[n,:] = 0.5*M*np.mean(Wx*Wx*X*X + VX*VX,0)\n",
    "    \n",
    "    if(showflag):\n",
    "        maxE = np.max(E[:,0]+E[:,1])\n",
    "        \n",
    "        plt.figure(figsize=(10,3))    \n",
    "        plt.plot(taxis*1e+15, Wtraj[:,0]*1e-12, 'r', label='Donor')\n",
    "        plt.plot(taxis*1e+15, Wtraj[:,1]*1e-12, 'b', label='Acceptor')\n",
    "        plt.ylabel('$Frequency$ (cm$^{-1}$)')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        plt.title('Frequency Trajectories')\n",
    "\n",
    "        plt.figure(figsize=(10,3))\n",
    "        plt.plot(taxis*1e+15, E[:,0]/maxE, 'r', label='$E_{donor}$')\n",
    "        plt.plot(taxis*1e+15, E[:,1]/maxE, 'b', label='$E_{acceptor}$')\n",
    "        plt.plot(taxis*1e+15, (E[:,0]+E[:,1])/maxE, 'k', label='$E_{total}$')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.title('Energy Profiles')\n",
    "        plt.show()\n",
    "\n",
    "    return E,Wtraj\n",
    "\n",
    "\n",
    "def fit_data(E, showflag):\n",
    "    maxE = np.max(E[:,0]+E[:,1])\n",
    "    ndxo = np.where(np.min(np.abs(taxis-(to+5.0*sigma)))==np.abs(taxis-(to+5.0*sigma)))[0][0]\n",
    "\n",
    "    xdata = (taxis[ndxo:]-taxis[ndxo])*1e+12\n",
    "    ydata = E[ndxo:,0]/maxE\n",
    "\n",
    "    def func(x, a, b, d):\n",
    "        return a * np.exp(-b * x)*np.cos(2.0*math.pi*d*x) + 0.5\n",
    "\n",
    "    guess = [0.5, 1.0, 5.0]\n",
    "    popt, pcov = curve_fit(func, xdata, ydata, guess)\n",
    "\n",
    "    if(showflag):\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot(xdata, ydata, 'k-', label='Raw data', linewidth=3)\n",
    "        plt.plot(xdata, func(xdata, *popt), 'r-', label='Fit: $\\\\tau_{EET} =$'+str(round((1.0/popt[1])*100)/100)+' ps', linewidth=3)\n",
    "        plt.plot(xdata, func(xdata, popt[0], popt[1], 0.0), 'b--', label='Exponential Component', linewidth=3)\n",
    "        plt.title('Fit Results')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return 1.0/popt[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EET Dynamics ##\n",
    "\n",
    "To get a sense for how the simulation works, execute the code block below, playing with the values of the parameters ``Delta`` and ``J``. ``Delta`` controls the strength of dynamic disorder -- i.e., the range of the frequency fluctuations for each oscillator -- while ``J`` controls the interaction strength between the two sites. Both parameters are normalized, so that values of ``J = Delta = 1`` represents a \"reasonable\" set of parameters, comparable to what one might see in a real Amide I experiment. \n",
    "\n",
    "Note that the last argument in the two functions ``calc_response()`` and ``fit_data()`` is a boolean flag which indicates whether or not the results should be plotted. When set to ``1`` (the default), the generated data is plotted graphically. When set to ``0``, the simulation runs but no figures are generated. \n",
    "\n",
    "To see how the EET rate depends on the value of the two parameters ``J`` and ``Delta``, execute the code below, starting with ``J = Delta = 1`` and then with a variety of parameter values, noting how each variable effects the EET time scale, reported as $\\tau_{EET}$ in the last plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 1.0\n",
    "Delta = 1.0\n",
    "\n",
    "E,Wtraj = calc_response(J, Delta, 1)\n",
    "tau = fit_data(E, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation of EET Rate with Site-to-Site Coupling ##\n",
    "\n",
    "Now that you have some feel for how the simulation works, let's see how the overall EET rate (one over the EET time) varies with the value of $J$. The code below repeats the EET simulation for values of $J$ ranging from one-tenth to ten-times our \"normal\" value. How does the EET rate vary with J? Why might this be? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta = 1.0 \n",
    "Jvec = np.arange(0.25, 10.0, 0.5)\n",
    "\n",
    "Delta = 1.0\n",
    "Tau = np.zeros(np.shape(Jvec))\n",
    "for n in range(0, len(Jvec)):\n",
    "    plt.close('all')\n",
    "    E,Wtraj = calc_response(Jvec[n], Delta, 0)\n",
    "    Tau[n] = fit_data(E, 0)\n",
    "\n",
    "plt.plot(Jvec, 1.0/Tau, 'o-', label='$k_{ET}$')\n",
    "plt.xlabel('Coupling Strength (arb. units)')\n",
    "plt.ylabel('$k_{ET}$ (ps$^{-1}$)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation of EET Rate with Dynamic Disorder ##\n",
    "\n",
    "Now that you have some idea how the EET rate varies with ``J``, let's study more closely its variation with ``Delta``. The cell below repeats our simulation scheme with ``J`` fixed and ``Delta`` varying from one-tenth to twice our \"standard\" value. (Note that the simulation becomes unstable when ``Delta`` is made too big, which is why we explore a more restricted range of values than with ``J``. How does the EET rate vary with ``Delta``? Why might this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 1.0\n",
    "Dvec = np.arange(0.1, 2.0, 0.1)\n",
    "Tau = np.zeros(np.shape(Dvec))\n",
    "for n in range(0, len(Dvec)):\n",
    "    E,Wtraj = calc_response(J, Dvec[n], 0)\n",
    "    Tau[n] = fit_data(E, 0)\n",
    "\n",
    "plt.plot(Dvec, 1.0/Tau, 'o-', label='$k_{ET}$')\n",
    "plt.xlabel('Dephasing Strength')\n",
    "plt.ylabel('$k_{ET}$ (ps$^{-1}$)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
